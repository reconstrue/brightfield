{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ffn_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTg48D9k1QnL",
        "colab_type": "text"
      },
      "source": [
        "# Flood-Filling Networks\n",
        "\n",
        "[![](https://1.bp.blogspot.com/-qhFmhCXejTU/XUxZtH7VkiI/AAAAAAAAEaE/BujQmSwAeWMuVLqrIbiooblVHp4NfLEtgCLcBGAs/s1600/image1.png)](https://ai.googleblog.com/2019/08/an-interactive-automated-3d.html)\n",
        "\n",
        "In connectomics, Google has two very interesting 2017 codebases, Flood-Filling Networks (FFNs) and Neuroglancer. The former is a neural network which performs image segmentation of volumes of brain slices to construct stick figure skeletons and 3D mesh models of detected neurons; the latter is an in-browser visualizer of the former’s results. Google’s Neuroglancer demo (live in-browser) works in any modern release of Chrome or Firefox.\n",
        "\n",
        "Along with the FFN algorithm, Google AI simultaneously released Neuroglancer, which is in-browser software for viewing the output of a FFN. Both codebases (neuron detector algorithm and visualizer) are licensed under Apache 2.0. For more detail see Google’s July 2018 introductory blog post, Improving Connectomics by an Order of Magnitude. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoQgwFIwzqai",
        "colab_type": "text"
      },
      "source": [
        "## Status\n",
        "\n",
        "Code (Apache-2.0 licensed) code was taken from Google's \n",
        "repro: [ffn_inference_demo.ipynb](https://github.com/google/ffn/blob/master/ffn_inference_demo.ipynb) and\n",
        "used here to seed probing if it could be run on Colab.\n",
        "\n",
        "This issue is being tracked on GitHub as [#73](https://github.com/reconstrue/brightfield_on_colab/issues/73).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JR0Ki2-A6E9y",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "The name \"flood filling\" is borrowed from previous, non-CNN algorithms. For example, skimage has [Flood Fill](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_floodfill.html). There is a given seed point and the algorithm floods neighboring points like water filling a watershed. \"The conceptual analogy is the ‘paint bucket’ tool in many graphic editors.\"\n",
        "\n",
        "### Neuroglancer\n",
        "\n",
        "In Neuroglancer, after about a minute of basic navigation – clicking and dragging on colored blobs – a user quickly gets the idea: Neuroglancer is a 3D spatial navigator of 2D black and white brain slice images, with “augmented reality” 3D mesh models of FFN-detected neurons, each highlighted with a distinct color.\n",
        "\n",
        "In November 2017, in partnership with the Max Planck Institute, Google released the Neuroglancer source code to support their paper, High-precision automated reconstruction of neurons with flood-filling networks, which was eventually published in Nature Methods. (Earliest related paper yet found is from November 2016.)\n",
        "\n",
        "### FFN\n",
        "\n",
        "The crux of the Flood Filling Networks (FFNs) work is a network architecture – essentially a CNN enhanced with a RNN – that can do colored image segmentation of black-and-white (electron microscopy) brain images, thereby reconstructing the imaged neurons in 3D. These FFNs (and at least two other examples, discussed herein) are ML-based automation tools with the potential to save many hours of tedius manual neurite tracing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agbF60UxgS4v",
        "colab_type": "text"
      },
      "source": [
        "## Intro journal papers\n",
        "\n",
        "The first paper is the 2016 pre-print, [Flood-Filling Networks (on arxiv)](https://arxiv.org/abs/1611.00421).\n",
        "\n",
        "The main FFN paper is entitled,\n",
        "\"High-precision automated reconstruction of neurons with flood-filling networks\" but the place to start reading might be Google's announcement blog post, [Improving Connectomics by an Order of Magnitude](https://ai.googleblog.com/2018/07/improving-connectomics-by-order-of.html).\n",
        "- [pre-print on biorxiv](https://www.biorxiv.org/content/10.1101/200675v1.full.pdf)\n",
        "- [Nature article ($)](https://www.nature.com/articles/s41592-018-0049-4)\n",
        "  - Nat Methods. 2018 Aug;15(8):605-610.  \n",
        "doi: 10.1038/s41592-018-0049-4.  \n",
        "2018 Jul 16.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LelRGtdKTid",
        "colab_type": "text"
      },
      "source": [
        "## Algorithm illustration\n",
        "\n",
        "\n",
        "Here are two Google illustrations of the FFN algorithm. The color yellow is the same in both (inference attention). Unfortunately, the other colors do not map between the two illustrations, rather black => red and red => blue. \n",
        "\n",
        "The yellow dot is the FFN’s attention mapping (flood filling) within a single neuron by bouncing off the cell’s walls.\n",
        "\n",
        "<img src=\"https://1.bp.blogspot.com/-GvN3s9zAd2E/WzQamIoyrMI/AAAAAAAADGU/UqSwCwOw7XQuBkk3iJQEpiHMRmEpt-hvgCLcBGAs/s1600/image3.gif\" hspace=\"14px\" vspace=\"7px\" />\n",
        "\n",
        "\n",
        "[![(c) Google: Improving Connectomics by an Order of Magnitude](https://3.bp.blogspot.com/-gaOWX7BKxMg/W0t7BBsWN-I/AAAAAAAADKs/l25qFCT1pK0MRRKXYppnHqQTu6OQdGnfQCLcBGAs/s1600/image4.gif)](https://ai.googleblog.com/2018/07/improving-connectomics-by-order-of.html)\n",
        "\n",
        "The above illustrates a run of FFN which (flood) fills one neuron at a time. The red is what is segmented/filled. The yellow is the inference algorithm working within a small cuboid of active field-of-view.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjndHGwnnJQA",
        "colab_type": "text"
      },
      "source": [
        "The following image sequence illustrates the sequential nature of the algorithm (in a dense volumetric EM context), i.e. cells are segmented one-by-one randomly.\n",
        "![(c) FFN Nature paper](http://reconstrue.com/projects/brightfield_neurons/demo_images/ffn_segmenting_sequence.png)\n",
        "\n",
        "\n",
        "FFNs have been successfully applied to dense volumetric EM data by Google and Max Panck. The question is: can this technology be adopted to single-neuron brightfield image stacks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBVT0sjbLnUb",
        "colab_type": "text"
      },
      "source": [
        "## Generating labels for training data\n",
        "\n",
        "There's lots of data; there's a lot less labeled data. Even not-great labels can some times be used for successful training.\n",
        "\n",
        "One interesting idea is to to use a Variational Auto-Encoder (VAE) to (label-less-ly) generate segmentation masks, and the masks are subsequently used as labels to train the FFN: [VAE output to train FFN](https://github.com/hasagar97/Flood-Filling-Networks) supposedly rather easy.\n",
        "\n",
        "**Step 1** Train VAE:\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/hasagar97/Flood-Filling-Networks/master/files/NN1_architecture.png\" width=\"50%\" />\n",
        "\n",
        "\n",
        "**Step 2** Use VAE output to train FNN:\n",
        "<img src=\"https://user-images.githubusercontent.com/473077/69997289-a297cb00-1508-11ea-98b6-6ced55ebf774.png\" width=\"75%\" />\n",
        "\n",
        "Hopefully, This might reduce training costs: \"architecture is computationaly easy to train.\" Easy doesn't necessarrily mean cheap.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyjbBy31t6et",
        "colab_type": "text"
      },
      "source": [
        "# FFN adoptions\n",
        "\n",
        "[Learning cellular morphology with neural networks](https://www.nature.com/articles/s41467-019-10836-3), Nature Communications volume 10, Article number: 2736 (2019).\n",
        "\n",
        "Say you wanted to remove all the glia from a chuck of dense volumetric EM imaged brain, making it easier to see certain neurons (glia are 90% of the cells in brains). Sure would be handy to have a CNN-ish classifier tool to filter out all the red glias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYV5Y2ANKpbo",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "\n",
        "### Code\n",
        "- Main repo: https://github.com/google/ffn \n",
        "  - (Apache-2.0)\n",
        "\n",
        "### Papers\n",
        "- First paper: [FFNs](https://arxiv.org/pdf/1611.00421.pdf)\n",
        "\n",
        "- Pre-prints: \n",
        "  - SECGAN: [Segmentation-Enhanced CycleGAN](https://www.biorxiv.org/content/biorxiv/early/2019/02/13/548081.full.pdf)\n",
        "  - CMN: [Learning cellular morphology with neural networks](https://www.biorxiv.org/content/10.1101/364034v2)\n",
        "\n",
        "\n",
        "### Blog posts and such \n",
        "\n",
        "- [Automated Reconstruction of a Serial-Section EM Drosophila Brain with Flood-Filling Networks and Local Realignment](https://fafb-ffn1.storage.googleapis.com/landing.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EddcddafQZEn",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/demo_images/cajal_1.png\" width=\"100%\" />\n"
      ]
    }
  ]
}