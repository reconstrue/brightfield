{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "K4MP7POkQ-PZ",
        "colab_type": "text"
      },
      "source": [
        "# Datasets\n",
        "\n",
        "![](https://reconstrue.github.io/brightfield_on_colab/content/images/651806289_minip_turbo_banner.png)\n",
        "\n",
        "Brightfield neuron datasets are measured in tens of gigabytes (GB). For example, the Allen Institute acquires images with an effective X-Y pixel size of 0.114 micron x 0.114 micron, slides of which are acquired at 0.28 μm depth increments. \"In mice, axonal diameters range from less than 0.2 μm up to 10 μm\" [[*](https://www.sciencedirect.com/topics/biochemistry-genetics-and-molecular-biology/axon)]. Visible light is in the range of 0.4 microns to 0.7 microns, blue to red respectively. So, the combination of the brightfield modality and size of the neurites means the acquired data is dirty by nature, making the neuron reconstruction software's task difficult."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOEtKoa7y5nZ",
        "colab_type": "text"
      },
      "source": [
        "## Data sources\n",
        "So far sample datasets have been exercised from:\n",
        "- The Allen Institute\n",
        "- ShuTu sample data\n",
        "\n",
        "It is also a goal to enable Colab users to upload (or link to) their own brightfield image stacks and then generate SWC files, on Colab. With a (currently nonexistant) pre-trained brightfield reconstruction model, this would simply be the inference phase of the hypothetical neuron detector model's lifecycle. \n",
        "\n",
        "Unfortunately image file formats are not particularly well defined so there is ETL data wrangling to be done. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUNBK_PAyeqX",
        "colab_type": "text"
      },
      "source": [
        "## Training corpus\n",
        "\n",
        "As with any open computer vision problem, a test corpus is extremely valuable for measure progress. For example, there is the [Standford Medical ImageNet](https://aimi.stanford.edu/research/medical-imagenet) but that is for radiology not brightfield neuroscience. More germane to this project, [The Allen Institute's Cell Type Database](data_sources/allen_institute/cell_types_db.html) has hundreds of brightfield neuron image stacks with \"labeled data.\" More relevant, they have already set out [a brightfield reconstruction challenge dataset](./allen_institute/brightfield_neuron_reconstruction_challenge.html), consisting of 105 training and 10 test specimen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "018m4_qcWh1Z",
        "colab_type": "text"
      },
      "source": [
        "## Input file types\n",
        "Neuron reconstruction input datasets have two parts:\n",
        "- image stacks: TIFF files off of a brightfield microscopes\n",
        "- skeletons: the `*.swc` files\n",
        "\n",
        "Both training and test neuron specimens come with image stacks. Only training neurons come with skeletons. The skeletons can be thought of as the classification labels for the training data, classifying each voxel as:\n",
        "- soma (1)\n",
        "- axon (2)\n",
        "- basal dendrite (3)\n",
        "- apical dendrite (4)\n",
        "- or extra-cellular"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ObJtqmJciiC",
        "colab_type": "text"
      },
      "source": [
        "### SWC files\n",
        "In the context of neuron reconstructor model training, the core analogy is data:labels::micrographs:skeletons.\n",
        "\n",
        "There is an unfortunate bit of nomenclatural history to the \"SWC\" name, as per the [SWC+ spec](https://neuroinformatics.nl/swcPlus/):\n",
        "> (S.W.C. encodes for the last names of its initial designers Ed Stockley, Howard Wheal, and Robert Cannon) \n",
        "\n",
        "The following is [an example SWC, rendered via Janelia's Sharkviewer](https://www.janelia.org/sharkviewer).\n",
        "\n",
        "<img src=\"https://reconstrue.github.io/brightfield_on_colab/content/images/sharkviewer.png\" width=\"60%\" />\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YKfuTvAcfM_",
        "colab_type": "text"
      },
      "source": [
        "### Image stack\n",
        "\n",
        "In the Allen Institute's Cell Type Database, individual image stacks average around 20 GB, with some as large as 60 GB.\n",
        "\n",
        "TIFF files are the standard image format for brightfield. TIFF uses 32-bit offsets which means TIFF file size maxes out at 4 GB. [BigTIFF](https://www.awaresystems.be/imaging/tiff/bigtiff.html) is a 64-bit.\n",
        "\n",
        "Sometimes image stacks are distributed as a single file, containing multiple [\"TIFF subfiles\"](https://en.wikipedia.org/wiki/TIFF#Multiple_subfiles) which is part of the core TIFF spec. Given the image stack size, BigTIFF is sometime the file format, not TIFF.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBL1gYa-Q-Pc",
        "colab_type": "text"
      },
      "source": [
        "The images might be rectilinear as in the case of data from the Allen Institute. Or the images might be the result of stitching, which may or may not be rectilinear. (The Allen's data is stitched, but it is also rectilinear as can be seen by subtle lighting banding artifacts in some images.) For example, the following virtual slide stitching image was produced by ShuTu.\n",
        "\n",
        "![(c) ShuTu](https://reconstrue.github.io/brightfield_on_colab/content/images/shutu_stitched.jpg)"
      ]
    }
  ]
}