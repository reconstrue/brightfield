{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ffn_intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTg48D9k1QnL",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "# Flood-Filling Networks\n",
        "\n",
        "[![](https://1.bp.blogspot.com/-qhFmhCXejTU/XUxZtH7VkiI/AAAAAAAAEaE/BujQmSwAeWMuVLqrIbiooblVHp4NfLEtgCLcBGAs/s1600/image1.png)](https://ai.googleblog.com/2019/08/an-interactive-automated-3d.html)\n",
        "\n",
        "In connectomics, Google has two very interesting 2017 codebases, Flood-Filling Networks (FFNs) and Neuroglancer. The former is a neural network which performs image segmentation of volumes of brain slices to construct stick figure skeletons and 3D mesh models of detected neurons; the latter is an in-browser visualizer of the former’s results. Google’s Neuroglancer demo (live in-browser) works in any modern release of Chrome or Firefox.\n",
        "\n",
        "In Neuroglancer, after about a minute of basic navigation – clicking and dragging on colored blobs – a user quickly gets the idea: Neuroglancer is a 3D spatial navigator of 2D black and white brain slice images, with “augmented reality” 3D mesh models of FFN-detected neurons, each highlighted with a distinct color.\n",
        "\n",
        "In November 2017, in partnership with the Max Planck Institute, Google released the Neuroglancer source code to support their paper, High-precision automated reconstruction of neurons with flood-filling networks, which was eventually published in Nature Methods. (Earliest related paper yet found is from November 2016.)\n",
        "\n",
        "The crux of the Flood Filling Networks (FFNs) work is a network architecture – essentially a CNN enhanced with a RNN – that can do colored image segmentation of black-and-white (electron microscopy) brain images, thereby reconstructing the imaged neurons in 3D. These FFNs (and at least two other examples, discussed herein) are ML-based automation tools with the potential to save many hours of tedius manual neurite tracing.\n",
        "\n",
        "Along with the FFN algorithm, Google AI simultaneously released Neuroglancer, which is in-browser software for viewing the output of a FFN. Both codebases (neuron detector algorithm and visualizer) are licensed under Apache 2.0. For more detail see Google’s July 2018 introductory blog post, Improving Connectomics by an Order of Magnitude. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoQgwFIwzqai",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "## Status\n",
        "\n",
        "Code (Apache-2.0 licensed) code was taken from Google's \n",
        "repro: [ffn_inference_demo.ipynb](https://github.com/google/ffn/blob/master/ffn_inference_demo.ipynb) and\n",
        "used here to seed probing if it could be run on Colab.\n",
        "\n",
        "This issue is being tracked on GitHub as [#73](https://github.com/reconstrue/brightfield_on_colab/issues/73).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agbF60UxgS4v",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "## Intro papers\n",
        "\n",
        "The first paper is the 2016 pre-print, [Flood-Filling Networks (on arxiv)](https://arxiv.org/abs/1611.00421).\n",
        "\n",
        "The main FFN paper is entitled,\n",
        "\"High-precision automated reconstruction of neurons with flood-filling networks\" but the place to start reading might be Google's announcement blog post, [Improving Connectomics by an Order of Magnitude](https://ai.googleblog.com/2018/07/improving-connectomics-by-order-of.html).\n",
        "- [pre-print on biorxiv](https://www.biorxiv.org/content/10.1101/200675v1.full.pdf)\n",
        "- [Nature article ($)](https://www.nature.com/articles/s41592-018-0049-4)\n",
        "  - Nat Methods. 2018 Aug;15(8):605-610.  \n",
        "doi: 10.1038/s41592-018-0049-4.  \n",
        "2018 Jul 16.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LelRGtdKTid",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "## Algorithm illustration\n",
        "[![(c) Google: Improving Connectomics by an Order of Magnitude](https://3.bp.blogspot.com/-gaOWX7BKxMg/W0t7BBsWN-I/AAAAAAAADKs/l25qFCT1pK0MRRKXYppnHqQTu6OQdGnfQCLcBGAs/s1600/image4.gif)](https://ai.googleblog.com/2018/07/improving-connectomics-by-order-of.html)\n",
        "\n",
        "The above illustrates a run of FFN which (flood) fills one neuron at a time. The red is what is segmented/filled. The yellow is the inference algorithm working within a small cuboid of active field-of-view.\n",
        "\n",
        "<img align=\"left\" src=\"https://1.bp.blogspot.com/-GvN3s9zAd2E/WzQamIoyrMI/AAAAAAAADGU/UqSwCwOw7XQuBkk3iJQEpiHMRmEpt-hvgCLcBGAs/s1600/image3.gif\" hspace=\"14px\" vspace=\"7px\" />\n",
        "\n",
        "Left is a close up view of the same algorithm. The color yellow is the same in both (inference attention). Unfortunately, between the two illustrations black => red and red => blue. \n",
        "\n",
        "The yellow dot is the FFN’s attention mapping (flood filling) within a single neuron by bouncing off the cell’s walls.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjndHGwnnJQA",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "The following image sequence illustrates the sequential nature of the algorithm (in a dense volumetric EM context), i.e. cells are segmented one-by-one randomly.\n",
        "![(c) FFN Nature paper](http://reconstrue.com/projects/brightfield_neurons/demo_images/ffn_segmenting_sequence.png)\n",
        "\n",
        "\n",
        "FFNs have been successfully applied to dense volumetric EM data by Google and Max Panck. The question is: can this technology be adopted to single-neuron brightfield image stacks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBVT0sjbLnUb",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "## Labeling training data\n",
        "\n",
        " [VAE output to train FFN](https://github.com/hasagar97/Flood-Filling-Networks) supposedly rather easy.\n",
        "\n",
        "A VAE architecture:\n",
        "\n",
        "![](https://raw.githubusercontent.com/hasagar97/Flood-Filling-Networks/master/files/NN1_architecture.png)\n",
        "\n",
        "Used to bootstrap training data for FNN.\n",
        "![Screen Shot 2019-12-02 at 13 35 15](https://user-images.githubusercontent.com/473077/69997289-a297cb00-1508-11ea-98b6-6ced55ebf774.png)\n",
        "\n",
        "That would seemingly reduce training costs: \"architecture is computationaly easy to train.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyjbBy31t6et",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "# FFN adoptions\n",
        "\n",
        "[Learning cellular morphology with neural networks](https://www.nature.com/articles/s41467-019-10836-3), Nature Communications volume 10, Article number: 2736 (2019).\n",
        "\n",
        "Say you wanted to remove all the glia from a chuck of dense volumetric EM imaged brain, making it easier to see certain neurons (glia are 90% of the cells in brains). Sure would be handy to have a CNN-ish classifier tool to filter out all the red glias."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYV5Y2ANKpbo",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "## References\n",
        "\n",
        "### Code\n",
        "- Main repo: https://github.com/google/ffn \n",
        "  - (Apache-2.0)\n",
        "\n",
        "### Papers\n",
        "- First paper: [FFNs](https://arxiv.org/pdf/1611.00421.pdf)\n",
        "\n",
        "- Pre-prints: \n",
        "  - SECGAN: [Segmentation-Enhanced CycleGAN](https://www.biorxiv.org/content/biorxiv/early/2019/02/13/548081.full.pdf)\n",
        "  - CMN: [Learning cellular morphology with neural networks](https://www.biorxiv.org/content/10.1101/364034v2)\n",
        "\n",
        "\n",
        "### Blog posts and such \n",
        "\n",
        "- [Automated Reconstruction of a Serial-Section EM Drosophila Brain with Flood-Filling Networks and Local Realignment](https://fafb-ffn1.storage.googleapis.com/landing.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EddcddafQZEn",
        "colab_type": "text",
        "tags": [
          "full_width"
        ]
      },
      "source": [
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/demo_images/cajal_1.png\" width=\"100%\" />\n"
      ]
    }
  ]
}
