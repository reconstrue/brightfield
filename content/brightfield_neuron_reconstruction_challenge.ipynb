{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "brightfield_neuron_reconstruction_challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRBjEChYaoYU",
        "colab_type": "text"
      },
      "source": [
        "# Brightfield Auto-Reconstruction Challenge\n",
        "\n",
        "# <img src=\"http://reconstrue.com/assets/images/reconstrue_logo_brandmark.svg\" width=\"42px\" align=\"top\" /> **Reconstrue**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYqiGtT5kp1q",
        "colab_type": "text"
      },
      "source": [
        "## Abstract\n",
        "\n",
        "For [the BioImage Informatics 2019 Conference](https://alleninstitute.org/events-training/bioimage-informatics-2019/), the Allen Institute issued a [Brightfield Auto-Reconstruction Challenge](https://alleninstitute.org/events-training/bioimage-informatics-2019/reconstruction-competition/). Neuron object recognition in brightfield microscopy is an open problem, currently necessitating many hours of manual neurite tracing. The Challenge's ~2.5 terabyte dataset is available for use in research on brightfield microscopy neuron reconstruction. \n",
        "\n",
        "This project is a collection of Jupyter notebooks that perform data analysis on the Challenge dataset. These notebooks were developed on and are hosted on Google Colab and so can be re-run by anyone wishing to reproduce the same analysis, without any software tooling set-up.\n",
        "\n",
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/colormapped_turbo.png\" width=\"100%\"/>\n",
        "\n",
        "## Legal\n",
        "\n",
        "Copyright 2019 Reconstrue LLC.\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9ueOYbWbncS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copyright 2019 Reconstrue LLC. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Knj40ly4biid",
        "colab_type": "text"
      },
      "source": [
        "This code can be found on GitHub, [@reconstrue/brightfield_neuron_reconstruction_on_colab](https://github.com/reconstrue/brightfield_neuron_reconstruction).\n",
        "\n",
        "## Status\n",
        "\n",
        "For those interested in the development status of this project, [project_status.ipynb](https://colab.research.google.com/drive/1NvAuQKygkbk-qoplbpMmR_JpZ56_2fQV#scrollTo=74p_szyZDhSK) contains a high level overview, as well as links into the git repo's issues and kanbans for further details.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "On Colab, a notebook's table of contents can be found in the left sidebar, which may be colapsed/hidden (behind an `>` in the upper left corner of the page).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFoENqqYV65",
        "colab_type": "text"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "For the Brightfield Auto-Reconstruction Challenge, the Allen Institute assembled a dataset containing 115 cells for use in an evalution competition. The dataset is about 2.5 terabytes in size, consisting of raw brightfield microscopy image stacks produced by the Allen Institute. \n",
        "\n",
        "The dataset also includes SWC files for 105 of those 115 cells. These SWCs contain neuron skeletons manually traced by human experts. These stick figures are the labels for the trainging data – the so called gold standards i.e. the best answers as manually generated by human experts involving many hours of tedious data entry a.k.a neurite tracing. \n",
        "\n",
        "That works out to a roughly 90%/10% split of the datase into train and test subsets. The challenge is to generate SWCs for the ten cells in the test set.\n",
        "\n",
        "This project presents the code for multiple methods of neuron reconstruction including ShuTu and U-Net, two methods used in the original Challenge at BioImage 2019. Current research is exploring ResNet and Flood-filling Networks (FFNs) techniques.\n",
        "\n",
        "The first step with any dataset is exploratory data analysis and visualization. For a hands-on visual exploration of one cell's data, see the notebook [initial_dataset_visualization.cell_651806289.ipynb](https://colab.research.google.com/drive/1BVoQ1sKxzcpIlDx-TISCLbSadxpETIf6).\n",
        "\n",
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/demo_images/651806289_cubehelix.png\" width=\"100%\" alt=\"MinIP(713686035, Turbo)\"/>\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O3UG3CDQuTd",
        "colab_type": "text"
      },
      "source": [
        "### Target audience\n",
        "This project uses the Brightfield Challenge dataset to train models for brightfield neuron skeletonization, which can subsequently be used in production. Both training and inference are computed on Colab, for free. \n",
        "\n",
        "The target audience has two parts:\n",
        "- Computer vision researchers building object recognizer (read: training)\n",
        "- Lab scientists processing raw brightfield z-stacks into SWC files (read: inference)\n",
        "\n",
        "The first audience is the computer vision software developers. This project provides Jupyter notebooks that perform data ETL, manifesting, and triaging. These notebooks perform set up and grunt data wrangling for using the dataset for training. Additionally, ample visualization tools are provided specific to the nature of data. These tools enables a developer to quickly get to the interesting part, with the tools to introspect the models and their output. For example, these notebooks: \n",
        "1. Access and download the dataset\n",
        "2. Process the data to generate SWC skeleton files\n",
        "3. Juxtapose new reconstruction SWCs alongside manual gold standard SWCs\n",
        "\n",
        "The second audience is the sole researcher with a raw image stack off of a microscope desiring to produce a SWC, as well as other visualization. This person doesn't want to train neural networks, they simply wish to upload their images and run software (with pre-trained ML models) that will make an SWC file and related renderings. This is the inference phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbRmgGUj15To",
        "colab_type": "text"
      },
      "source": [
        "## Background\n",
        "\n",
        "The goal of auto-reconstruction is to automate neurite tracing, traditionally performed manually. The following image is taken from [the challenge's home page on alleninstitute.org](https://alleninstitute.org/events-training/bioimage-informatics-2019/reconstruction-competition/). It illustrates the objective of this exercise: the input is grayscale microscope images of an individual neuron; the output is a 3D stick figure of the neuron. \n",
        "\n",
        "In this image there are three examples, each in a separate column. The pairs of images consist of one grayscale camera image (a projection of the input) and one corresponding skeleton (the output) rendered in neon color on a dark field.\n",
        "\n",
        "<img src=\"https://alleninstitute.org/files/resources/1564545471/2651/\" alt=\"(c) Allen Institute\" width=\"100%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXUqajwjYdN1",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### Brightfield modality\n",
        "\n",
        ">The majority of dendritic and axonal morphology reconstructions to date are based on bright-field microscopy (Halavi et al., 2012), due to its broad compatibility with histological staining methods...\n",
        ">Moreover, the ability to enhance the signal intensity by counterstaining renders bright-field microscopy largely unsurpassed for reconstructions of whole axonal arbors up to the very thin (and typically faint) terminals. [[Parekh and Ascoli, 2013](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3653619/)]\n",
        "\n",
        "In [brightfield microscopy](https://en.wikipedia.org/wiki/Bright-field_microscopy), a single neuron is pumped full of biocytin to stain its insides black, while the rest of the specimen's brain tissue is chemically cleared to be translucent. In other words, there is a single dark/opaque foreground object – a biocytin stained neuron, the object of interest – which is imaged upon some essentially translucent background (or \"field\"). The field is bright (because of light shining through it) and the foreground is more opaque and so appears dark, ergo \"brigthfield.\"\n",
        "\n",
        "\n",
        "For a quick-and-dirty overview of the actual wet bench rigmarole involved in generating the biocytin stained samples, see the 8 minute vidoe in [Immunostaining of Biocytin-filled and Processed Sections for Neurochemical Markers](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5264554/) (2016). There is also [an 11 minute 2018 video on JoVE](https://www.jove.com/video/58592/biocytin-recovery-3d-reconstructions-filled-hippocampal-ca2), walking through the nitty-gritty wet bench protocol for imaging neurons with biocytin, which demonstrates manual neuron tracing via Neurolucida.\n",
        "\n",
        "For a backgrounder, see the 2007 article out of the Max Planck Institute, [Transmitted light brightfield mosaic microscopy for three-dimensional tracing of single neuron morphology](https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-12/issue-06/064029/Transmitted-light-brightfield-mosaic-microscopy-for-three-dimensional-tracing-of/10.1117/1.2815693.full?SSO=1), or see PubMed for more on [using biocytin to stain and trace neurons](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3368650/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13D0zeM9Sa49",
        "colab_type": "text"
      },
      "source": [
        "### Reconstruction: an unsolved problem\n",
        "\n",
        "Brightfield neuron reconsturction is an open image processing problem, and a rate limiting factor in brightfield microscopy. Currently, brightfield neuron reconstruction involves manual labor comprising many hours of manually tracing skeletons from the raw brightfield image stacks. \n",
        "\n",
        "Brightfield microscopes are the simplest and most common type of microscope, so solving this problem could enable many labs to perform image analysis more quickly. This means that brightfield reconstruction software is more widely used, compared to other microscopy modalities. Brightfield is a relatively low tech microscopy modality that produces great results.\n",
        "\n",
        "From the computer vision perspective, [natural intelligence object recognition may be based on skeletons](https://www.scientificamerican.com/article/no-bones-about-it-people-recognize-objects-by-visualizing-their-skeletons/) so this problem for neuroscience may feedback to the artificial intelligence community, specifically the visual object recongition folks. Recurrent networks are a promising candidate for this mode of microscopy data.\n",
        "\n",
        "For a backgrounder, check out [Neuronal Morphology Goes Digital: A Research Hub for Cellular and System Neuroscience](https://www.sciencedirect.com/science/article/pii/S0896627313002328) Parekh & Ascoli (2013, in Neuron). Here's an image from that paper illustrating the diversity of neuron morphologies across species:\n",
        "\n",
        "<img src=\"https://ars.els-cdn.com/content/image/1-s2.0-S0896627313002328-gr1.jpg\" width=\"100%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFN1iYOLoX_T",
        "colab_type": "text"
      },
      "source": [
        "## Dataset analysis\n",
        "\n",
        "In this project, Google Colab is used as a platform for reproducable research, specifically image analysis of biocytin stained neurons imaged via brightfield microscopy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G3mUuEW46Bh0",
        "colab_type": "text"
      },
      "source": [
        "### Platform: Google Colab\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USzcZfq0B4pu",
        "colab_type": "text"
      },
      "source": [
        "This project consists of Jupyter notebooks tuned up to run on Google Colab. The Colab service is Google's free Jupter hosting service, packaged silimar to Google Sheets and Docs. An optional Nvidia GPU can be requested, useful for, say, [GPU accelerated U-Net](https://ngc.nvidia.com/catalog/model-scripts/nvidia:unet_industrial_for_tensorflow).\n",
        "\n",
        "Jupyter notebooks are a popular medium for doing data science. Notebooks are a medium within which both computer programmers and neuroscientist are comfortable. \n",
        "\n",
        "Colab is used to both perform analysis (e.g. generate projects and skeletons) and to publish results in pre-run notebooks. The curious can also re-run the notebooks to reproduce the results, or use the notebooks as workflow vignettes to spin off of.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHuOVudlI-4n",
        "colab_type": "text"
      },
      "source": [
        "### Dataset specifics\n",
        "\n",
        "The data is collected from a slice of brain sandwiched between a glass slide and a cover slip. The microscope's field of view is much smaller than the slide so the slice is imaged tile by overlapping tile. The tiles are then stitched together to make a single 2D image, a virtual plate. \n",
        "\n",
        "The third dimension of the image stack is created as the neuron is moved through the microscopes's field of view by a motorized stage upon which the specimen slide is mounted. The stage drops about 5 micrometers at a step.\n",
        "\n",
        "An artifact of this technique is that the images at the top and the bottom of the stack seem blurry, which is caused by the darkly stained neuron being out-of-focus – the so called [bokeh effect](https://en.wikipedia.org/wiki/Bokeh), \"the way the lens renders out-of-focus points of\" darkness.\n",
        "\n",
        "The specifics of how the data in the Challenge dataset was collected can be found in The Allen's documentation, Allen Cell Types Database whitepaper, Cell Morphology And Histology, [CellTypes_Morph_Overview.pdf](http://help.brain-map.org/download/attachments/8323525/CellTypes_Morph_Overview.pdf?version=4&modificationDate=1528310097913&api=v2):\n",
        "\n",
        ">Serial images (63X magnification) through biocytin-filled neurons...\n",
        "\n",
        ">Individual cells were imaged at higher resolution for the purpose of automated and manual reconstruction.\n",
        "Series of 2D images of single neurons were captured with a 63X objective lens (Zeiss Plan APOCHROMAT\n",
        "63X/1.4 oil, 39.69x total magnification, and an n oil-immersion condenser 1.4 NA), using the Tile & Position and\n",
        "Z-stack ZEN 2012 SP2 software modules (Zeiss). The composite 2D tiled images with X-Y effective pixel size\n",
        "of 0.114 micron x 0.114 micron were acquired at an interval of 0.28 µm along the Z-axis. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip5clQ-i3qH7",
        "colab_type": "text"
      },
      "source": [
        "### Initial dataset exploration\n",
        "\n",
        "Before actually demostrating reconstruction code, first let's explore the challenge dataset, in a Jupyter notebook, [dataset_manifest.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=akBdiF6snGGo)\n",
        "\n",
        "Initial dataset exploration\n",
        "  - [dataset_manifest.ipynb](https://colab.research.google.com/drive/1_zv9mgrKVCMa5jTnN1CADZFRi3UES6_P#scrollTo=FQQb1m85EkvC): file level overview of dataset; creates `specimens_manifest.json`\n",
        "  - [initial_dataset_visualization.ipynb](https://colab.research.google.com/drive/1ZxzDwD1UdYqhuTxckPLiOUYHin0MZmFQ#scrollTo=TaREcuFG6SSQ): visual deep dive of a single specimen's imagery; uses `specimens_manifest.json`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSMn5S-oXeMI",
        "colab_type": "text"
      },
      "source": [
        "## Reconstruction methods\n",
        "\n",
        "In response to the original BioImage 2019 challenge, there were two skeleton reconstruction methods that were initially evaluated:\n",
        "\n",
        "- ShuTu\n",
        "- U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Bk_D7jTF1Uq",
        "colab_type": "text"
      },
      "source": [
        "### ShuTu\n",
        "\n",
        "Status: ShuTu CLI reconstruction code is working on Colab, as of 2019-10-12, with only a bit of work needed to get the Allen data into a format ShuTu likes (multi-page TIFF) \n",
        "\n",
        "<img src=\"http://personal.psu.edu/dzj2/ShuTu/ShuTu_cell_char.jpg\" width=\"100%\"/>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVgZMuzMVTtH",
        "colab_type": "text"
      },
      "source": [
        "ShuTu notebooks:\n",
        "  - **TBD:** ShuTu generating SWC for Allen data\n",
        "    - [shutu_makes_swc_for_neuron_651806289.ipynb](https://colab.research.google.com/drive/1CczIvOKomTQexPznDIqb5wErnWJYlBTn#scrollTo=D0T393yXh-a_)\n",
        "    - This is the main ShuTu notebook; the rest are earlier steps\n",
        "  - ShuTu generating SWC for ShuTu demo data\n",
        "    - [brightfield_neuron_swc_by_shutu.ipynb](https://colab.research.google.com/drive/1zdTS1HsAqdH5p4sk42TC6-uFM7f7XUdA#scrollTo=8aBV9zEcLJHm)\n",
        "  - ShuTu installing on Colab\n",
        "    - [install_shutu_on_colab.ipynb](https://colab.research.google.com/drive/1wRnt5ceTs2Oau4g_BiYv09ZOLbv3cyWI#scrollTo=Q1eCY1mvHbCr) \n",
        "  - ShuTu on Colab first test     \n",
        "    - [first_manual_install_of_shutu_on_colab.ipynb](https://colab.research.google.com/drive/1PQEWuFjUi3vo-1btNi6M5vXoNS3dTv5o#scrollTo=qQ5T40Rh0gJk)\n",
        "\n",
        "ShuTu (Chinese for “dendrite”) is open source for neurite reconstruction. See the notebook, [ShuTu on Colab](https://colab.research.google.com/drive/1PQEWuFjUi3vo-1btNi6M5vXoNS3dTv5o#scrollTo=qQ5T40Rh0gJk), for how ShuTu can generate SWC files from brightfield image stacks. \n",
        "\n",
        "ShuTu demo datasets have been seen at around 2 GB. Smallest cell in the challenge dataset is ~6 GB; the average is ~20MB. Perhaps ShuTu on Colab can works for at least some cells. Larger might not work as ShuTu distributes work via MPI, but Colab only gives you one core so that doesn't scale on Colab. But MPI tools seem to be preinstalled on Colab so that's a good thing WRT using Colab as a free-tier demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJBUov2BYd4-",
        "colab_type": "text"
      },
      "source": [
        "### U-Net\n",
        "\n",
        "U-Net is tracked, on GitHub, in [#30: U-Net](https://github.com/reconstrue/brightfield_neuron_reconstruction/issues/30).\n",
        "\n",
        "U-Net is the current workhorse for cell imaging. The trick here is to do it on Colab, leveraging a GPU, with the correct variant of U-Net.\n",
        "\n",
        "- Reconstruction method #2: U-Net\n",
        "  - **TBD:** U-Net method: [brightfield_neuron_swc_by_unet_on_colab.ipynb](https://colab.research.google.com/drive/1mbxnqpaU8l17yayCdW-LlYbHb-yXQvqO#scrollTo=TsepXS09_0Qs)\n",
        "- **TBD:** SWC Evalutator: [skeleton_juxtaposer.ipynb](https://colab.research.google.com/drive/1Hj7r49ObIht5YOK6Scz61BxFkFoN76pB#scrollTo=kDsVnYFtIKpa)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRyDH27Emuvt",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"http://reconstrue.com/projects/brightfield_neurons/colormapped_viridis.png\" width=\"100%\" alt=\"Viridis colormap example\"/>\n"
      ]
    }
  ]
}