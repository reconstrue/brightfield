{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "colab": {
      "name": "cell_types_db.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "sgkIEaR9K9sf",
        "colab_type": "text"
      },
      "source": [
        "# Cell Types Database\n",
        "\n",
        "![651806289 MinIP](http://reconstrue.com/projects/brightfield_neurons/demo_images/651806289_minip_cubehelix_wide.png)\n",
        "\n",
        "[The Cell Types Database](http://celltypes.brain-map.org/) is one of the basis data products produced by The Allen Institute. They are constructing an altas of type of cells found in brains of mice and humans. For a primer with contextual history, state of the art, and goals related to the Cell Types Database, see the Allen Institute's 36 minute talk on the subject, presented at their 2019 Showcase symposium: [Cell Types: From Data to Taxonomy to Product](https://www.youtube.com/watch?v=NCTq7GHakqg).\n",
        "\n",
        "\n",
        "There are multiple ways the cells are represented in the database: electrophysiology spike train recordings, transcriptomics, simulation models (GLIF or perisomatic), etc. Of particular interest for this project is the morphology data â€“ the skeletons in the `*.swc` files.\n",
        "\n",
        "The Allen has [about 500 SWC files for mouse neurons](http://celltypes.brain-map.org/data?donor__species=Mus%20musculus&nr__reconstruction_type=[full,dendrite-only]). Those ~500 are inside the red circle in the following Venn diagram of all mouse neurons in the Cell Types DB.\n",
        "\n",
        "![](http://reconstrue.com/projects/brightfield_neurons/demo_images/brain_map_venn.png)\n",
        "\n",
        "The main problem from The Allen's perspective is that they would like to have the red circle be a big as the main outer circle. It takes many hours to manually trace skeletons. The Allen processes hundreds of such cells a year. This is a serious manual labor bottleneck.\n",
        "\n",
        "It would seem like this sort of task would be a perfect candidate for automation via deep learning, CNNs, and related recent advances in computer vision. Unfortunately, this is proving to be nontrivial; algorithmic improvements in the last few years are starting to make larger projects feasible. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EevnK0RgYDRW",
        "colab_type": "text"
      },
      "source": [
        "## Data access options\n",
        "\n",
        "The data can be accessed 3 ways:\n",
        "- Web UI at brain-map.org\n",
        "- RMA, the Allen's RESTful HTTP API\n",
        "- Programatically via Allen SDK (Python)\n",
        "\n",
        "This is a Jupyter notebook of Python code so the Allen SDK is the natural way to go about accessing the data. Sometimes allensdk does not have an existing method to access some bit of data, in which case RMA is the fallback.\n",
        "\n",
        "\n",
        "A nice feature of the Allen Institute's set-up is that they do not require *any* auth to get to the public data in any of the three methods listed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uCYu0hVY3gc",
        "colab_type": "text"
      },
      "source": [
        "### brain-map.org web UI\n",
        "\n",
        "[brain-map.org](http://brain-map.org) is where the target images reside. The repository has a web UI, wherein the image stack can be viewed. Here is an example from their documentation [[*](http://help.brain-map.org/display/celltypes/Physiology+and+Morphology)]:\n",
        "\n",
        ">displays two orthogonal projections of the biocytin filled neuron and the neuron's 3D morphology reconstruction. From this page, you can also view the stack of high resolution images used for the reconstruction.\n",
        "\n",
        "![](http://help.brain-map.org/download/attachments/8323624/MorphBrowse.PNG?version=1&modificationDate=1476664307214&api=v2)\n",
        "\n",
        "So, we can explore the web UI to preview what the images look like but we want to download them via Python code:\n",
        "\n",
        "> You can also access the data programatically and obtain sample code to run your own model simulations. For more details go to the Download page. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWwgpgDeZFo7",
        "colab_type": "text"
      },
      "source": [
        "### RESTful RMA\n",
        "\n",
        "The second way to access the data is through the RESTful \"RMA\" interface. This is the core way to get **all** data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g0Oo9T38ZWbS",
        "colab_type": "text"
      },
      "source": [
        "### Allen SDK\n",
        "\n",
        "The Allen Institute first came up with a RESTful interface to their resources, called [RMA](http://help.brain-map.org/pages/viewpage.action?pageId=5308449). RMA is a [HATEOAS](https://restfulapi.net/hateoas/) style RESTful API. Later they added the Python SDK as client-side convenience wrapper code around the RMA.\n",
        "\n",
        "The `allensdk` is Python code which provides a programmatic interface to the info available via RMI. It also maintains a cache of files for performance purposes (`allensdk.core.cell_types_cache.CellTypesCache`).\n",
        "\n",
        "Although `allensdk` can provide metadata about cells in the repository, it does not have methods to acquire the raw image stack. To get the raw images, RMI is the only method. So, `allensdk` can provide IDs of available cells, but further work is required to then iterate through the stack and grab each file.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRYNEovYaERH",
        "colab_type": "text"
      },
      "source": [
        "## Explore RESTful RMA\n",
        "\n",
        "Their documentation includes [example URLs for fetching data](http://help.brain-map.org/display/celltypes/API#API-morphology_image_download). Let's express those in a Jupyter notebook.\n",
        "\n",
        "json_query_url = \"http://api.brain-map.org/api/v2/data/query.json?criteria=model::ProjectionImage,rma::criteria,[specimen_id$eq313862022]\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BZL_pHqbIhG",
        "colab_type": "text"
      },
      "source": [
        "### Set up\n",
        "\n",
        "#### Installations\n",
        "\n",
        "As discussed in the previous notebook, [allensdk.ipynb](http://reconstrue.com/data_sources/allen_institute/allensdk_on_colab.html), the Allen SDK needs to be installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8xQsmUobNIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "85498b59-e14b-4291-e547-bb10a3b47f7d"
      },
      "source": [
        "# Simple install way unfortunately causes version fights about pandas\n",
        "#!pip3 -q install allensdk\n",
        "#!pip3 show pandas\n",
        "\n",
        "# This way has a tweaked requirements.txt, avoiding error messages\n",
        "!pip3 install -q git+git://github.com/reconstrue/AllenSDK"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for allensdk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hUKo-coaF75",
        "colab_type": "text"
      },
      "source": [
        "### Images into markdown\n",
        "\n",
        "First up would be simply an image in markdown, using their sample URL :\n",
        "> [`http://api.brain-map.org/api/v2/section_image_download/323637357`](http://api.brain-map.org/api/v2/section_image_download/323637357)\n",
        "\n",
        "That image is a JPEG, less than 2 MB, ~5k x ~7k pixels. According to the docs:\n",
        ">images were first stitched from tiles in Tiff format, white balanced and finally converted to JPEG 2000 file format. Aperio ScanScope images were first converted to JPEG 2000 format, then orientation adjusted and white balanced. In either case, the final products were images in JPEG 2000 compressed format for further pipeline processing and analysis.\n",
        "\n",
        "\n",
        "The square grid is an artifact of the image tile stitching algorithm that has been used to assemble this whole slide image:\n",
        "\n",
        "<img src=\"http://api.brain-map.org/api/v2/section_image_download/323637357\" height='450px' />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDWymSKEaLvj",
        "colab_type": "text"
      },
      "source": [
        "### Images into Python\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiN8MHfeaUvZ",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#### URL encode queries\n",
        "First thing to note, some of the examples they give work but need to be URL encoded otherwise, results will come back but not be what is to be expected. For example, they provide an example:\n",
        "```\n",
        "http://api.brain-map.org/api/v2/data/query.json?criteria=model::ProjectionImage,rma::criteria,[specimen_id$eq313862022]\n",
        "```\n",
        "That will return some JSON but not just about specimen_id 313862022.\n",
        "\n",
        "But URL encode it and it works as expected:\n",
        "```\n",
        "http://api.brain-map.org/api/v2/data/query.json?criteria=model%3A%3AProjectionImage%2Crma%3A%3Acriteria%2C%5Bspecimen_id%24eq313862022%5D\"\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS4PmDUgaadW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download an image file\n",
        "\n",
        "#an_img_url = \"http://api.brain-map.org/api/v2/section_image_download/321549675\"\n",
        "an_img_url = \"http://api.brain-map.org/api/v2/section_image_download/323637357\"\n",
        "an_img_file_name = \"/content/an_image\"\n",
        "!wget --no-verbose --progress=bar:force:noscroll -O {an_img_file_name} {an_img_url} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySJJGYLIaewf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get stats on image file just downloaded\n",
        "print(f\"Detected image file type: {imghdr.what(an_img_file_name)}\")\n",
        "!echo -----------\n",
        "!ls -lh {an_img_file_name}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JO3m2Iftaj1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ffprobe {an_img_file_name}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMxjTbYpam2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "slide_img = PIL.Image.open(an_img_file_name)\n",
        "display(slide_img)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zpIr1XNaXaH",
        "colab_type": "text"
      },
      "source": [
        "### Request styles\n",
        "\n",
        "Seemingly when querying, data can be requested in multiple formats: XML, JSON, and CSV.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHjtA84Ra5bK",
        "colab_type": "text"
      },
      "source": [
        "### As XML"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0K7GLKc6cZYZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xml_request_url = \"http://api.brain-map.org/api/v2/data/query.xml?criteria=model::ProjectionImage,rma::criteria,[specimen_id$eq313862022]\"\n",
        "xml_file_name = \"response.xml\"\n",
        "!wget -O {xml_file_name} {xml_request_url}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3KpWxe1cgvP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat {xml_file_name}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKXQn2SKck_G",
        "colab_type": "text"
      },
      "source": [
        "That's nice: for each image stack, they provide both MaximumIntensityProjection and MinimumIntensityProjection from both the frontal view plane (xy) and one of the two side views (yz plane)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_NkE67edl49",
        "colab_type": "text"
      },
      "source": [
        "### As JSON\n",
        "\n",
        "This is exactly the same as the above XML response, except in the requested URL `/query.xml?` is changed to `/query.json?` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1isvBdPGdlOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file_name = \"/content/response.json\"\n",
        "\n",
        "query_url_root = 'http://api.brain-map.org/api/v2/data/query.json?criteria='\n",
        "query_encoded = urllib.parse.quote('model::ProjectionImage,rma::criteria,[specimen_id$eq313862022]')\n",
        "json_query_url = query_url_root + query_encoded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2FJlpV0drgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O {json_file_name} {json_query_url}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61Rj52MwduLY",
        "colab_type": "text"
      },
      "source": [
        "Cell Types DB docs say [[*](http://help.brain-map.org/display/celltypes/API#API-download_swc)]:\n",
        "> The API provides programmatic access to the microscopy images used for reconstruction, axis-oriented projections of those images, and morphological reconstructions.  A cell can have up to four axis-oriented projections of the images used for reconstruction:\n",
        "- XY minimum intensity projection\n",
        "- YZ minimum intensity projection\n",
        "- XY maximum intensity projection\n",
        "- YZ maximum intensity projection\n",
        "\n",
        "> The reconstruction images display a dark, biocytin-filled cell on a light background. The maximum intensity projections are constructed from inverted and contrast-enhanced versions of the morphology images, resulting in a light cell on a dark background.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmCUv5Jkdv-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(json_file_name) as f:\n",
        "  eg_data = json.load(f)\n",
        "\n",
        "print(json.dumps(eg_data, indent=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3PjhlgNd1De",
        "colab_type": "text"
      },
      "source": [
        "So, the above is saying that for specimen_id `13862022` there are 4 image available:\n",
        "- 2 Min intensity projections (XY plane and YZ plane)\n",
        "- 2 Max intensity projections (XY plane and YZ plane)\n",
        "\n",
        "For brightfield, the more natural projection is minimum, not maximum, and the XY project is the more interesting of the two part mugshot projections. So, we want the one with:\n",
        "```\n",
        "\"image_type\": \"MinimumIntensityProjection - xy\"\n",
        "```\n",
        "Or equivalently: `projection_function` == min and `axes` == xy.\n",
        "\n",
        "Finally, for a download URL, grab that projection's `id` and stick it on the end end of the following:\n",
        "```\n",
        "http://api.brain-map.org/api/v2/section_image_download/\n",
        "```\n",
        "\n",
        "For example,\n",
        "```\n",
        "http://api.brain-map.org/api/v2/section_image_download/323637357\n",
        "```\n",
        "\n",
        "Which, in markdown at width=200px looks like:\n",
        "\n",
        "<img src=\"http://api.brain-map.org/api/v2/section_image_download/323637357\" width=\"200px\" />\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp36A_kGd-ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "minips_collection_url = \"http://api.brain-map.org/api/v2/section_image_download/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzLZbR8Ad_sO",
        "colab_type": "text"
      },
      "source": [
        "#### Query full image stack\n",
        "\n",
        "http://help.brain-map.org/display/celltypes/API:\n",
        ">Find all images used for reconstruction for a layer 4 spiny cell (Specimen 313862022)\n",
        "```\n",
        "http://api.brain-map.org/api/v2/data/query.xml?criteria=\n",
        "model::SubImage\n",
        ",rma::criteria,data_set[specimen_id$eq313862022]\n",
        "![alt text](https://)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8LrYmRqeEO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file_name = \"/content/response.json\"\n",
        "\n",
        "query_terms = f'model::SubImage,rma::criteria,data_set[specimen_id$eq{cell_id}]'\n",
        "\n",
        "query_url_root = 'http://api.brain-map.org/api/v2/data/query.json?criteria='\n",
        "query_encoded = urllib.parse.quote(query_terms)\n",
        "json_query_url = query_url_root + query_encoded\n",
        "\n",
        "!wget -O {json_file_name} {json_query_url}\n",
        "\n",
        "with open(json_file_name) as f:\n",
        "  eg_data = json.load(f)\n",
        "\n",
        "print(json.dumps(eg_data, indent=2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txECSdcKeDcR",
        "colab_type": "text"
      },
      "source": [
        "Seems they all have `data_set_id`: 321549626 so that is the ID of the image stack? Or is the stack only part of it?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wl2yNcoGeQRg",
        "colab_type": "text"
      },
      "source": [
        "### RmaApi\n",
        "\n",
        "The above sort of query construction gets old quick, and is just sloppy and lame. So, the Allen folks have Python utility classes for such tasks: [RMA Database and Service API](http://alleninstitute.github.io/AllenSDK/data_api_client.html).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMZ2YFppeVbm",
        "colab_type": "text"
      },
      "source": [
        "### ImageDownloadApi\n",
        "\n",
        "http://alleninstitute.github.io/AllenSDK/allensdk.api.queries.image_download_api.html#allensdk.api.queries.image_download_api.ImageDownloadApi\n",
        "\n",
        "Note:\n",
        ">By default, an unfiltered full-sized image with the highest quality is returned as a download if no parameters are provided."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utLxV6n8eZEA",
        "colab_type": "text"
      },
      "source": [
        "### To Pandas\n",
        "\n",
        "The JSON is shaped ala:\n",
        "```json\n",
        "{\n",
        "  \"success\": true,\n",
        "  \"id\": 0,\n",
        "  \"start_row\": 0,\n",
        "  \"num_rows\": 50,\n",
        "  \"total_rows\": 2686,\n",
        "  \"msg\": [\n",
        "    {\n",
        "```\n",
        "There is some pagination going on via `start_row`, `num_rows`, and `total_rows`.\n",
        "\n",
        "The `msg` array is what we want to feed to Pandas. Here's a hacky, lazy way to perform that task via `pandas.read_json`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41vRMdRGebU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rows_json = eg_data[\"msg\"]\n",
        "\n",
        "# Write to FS\n",
        "processed_json_file_name = \"/content/query_trimmed.json\"\n",
        "with open(processed_json_file_name, 'w') as json_dest_file:\n",
        "  json.dump(rows_json, json_dest_file) \n",
        "\n",
        "# Test file just written to\n",
        "with open(processed_json_file_name) as f:\n",
        "  test_data = json.load(f)\n",
        "\n",
        "print(json.dumps(test_data, indent=2))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHbwvLkiedsv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# specimen_id is the id of the cell imaged, id is the id of an image\n",
        "query_df = pd.read_json(processed_json_file_name)\n",
        "DataTable(query_df.sort_values(by=['id'])) # Adds filtering UI"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfUGllwNei5R",
        "colab_type": "text"
      },
      "source": [
        "### Count mouse SWC files\n",
        "\n",
        "The Allen Institute's brain-map.org has data on many neurons, not all of which can/should be used to train ML models. The AllenSDK can be used ot query for a count of the number of mouse neuron cells that have both brightfield image stacks and SWC skeletons files.\n",
        "\n",
        "\n",
        "- [cell_types_cache Python source code](https://alleninstitute.github.io/AllenSDK/_modules/allensdk/core/cell_types_cache.html)\n",
        "- [Example Python usage](https://allensdk.readthedocs.io/en/latest/_static/examples/nb/cell_types.html#Cell-Morphology-Reconstructions)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hOBDDtQelfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allensdk.core.cell_types_cache import CellTypesCache\n",
        "from allensdk.api.queries.cell_types_api import CellTypesApi\n",
        "import pprint\n",
        "pp = pprint.PrettyPrinter(indent=4)\n",
        "\n",
        "ctc = CellTypesCache(manifest_file='cell_types/manifest.json')\n",
        "\n",
        "cells = ctc.get_cells(require_reconstruction=True, require_morphology=True, species=[CellTypesApi.MOUSE])\n",
        "print('Number of mouse cells with images and SWC files: %i' % len(cells))\n",
        "\n",
        "\n",
        "pp.pprint(cells[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKqfDGNmeoo3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: junk\n",
        "# this saves the NWB file to 'cell_types/specimen_464212183/ephys.nwb'\n",
        "# cell_specimen_id = 464212183\n",
        "# data_set = ctc.get_ephys_data(cell_specimen_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RGFURfCepot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls cell_types"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5L0AjDrTeujR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cells_df = pd.DataFrame(cells).sort_values(by=['id'], ascending=False)\n",
        "DataTable(cells_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtKubxotmxb7",
        "colab_type": "text"
      },
      "source": [
        "## Brightfield training data\n",
        "\n",
        "From a model training perspective, the skeleton in an SWC file can be seen as the \"labels\" for \"the labeled training data.\" For training purposes, we're only interested in the subset of cells in the atlas Cell Types Database that have skeletons and a microscopy image stack. The image stack is the input the machine to be built, and the SWC file is the output. Each SWC files represents many hours of manual labor by trained specialists reviewing and editing the SWC file.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "D7KiUaYUK9sm",
        "colab_type": "code",
        "outputId": "e4030eb0-4866-449c-8feb-cef058e5d532",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Query the Cell Types DB for files with skeletons a.k.a. reconstructions\n",
        "\n",
        "# via https://allensdk.readthedocs.io/en/latest/cell_types.html#cell-types-cache\n",
        "from allensdk.core.cell_types_cache import CellTypesCache\n",
        "\n",
        "ctc = CellTypesCache(manifest_file='cell_types/manifest.json')\n",
        "\n",
        "# a list of cell metadata for cells with reconstructions, download if necessary\n",
        "cells = ctc.get_cells(require_reconstruction=True)\n",
        "print('Number of cells with SWC files: %i' % len(cells))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of cells with SWC files: 637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "EawG7LJOK9sq",
        "colab_type": "text"
      },
      "source": [
        "Some of those are human cells, atop the roughly 500 mouse cells. Humans brains are much bigger than mouse brains. Training should focus on one species. The Allen has many more mouse neurons than human neurons. So, train on mouse neurons only. To query for \"mouse neurons only\" via the SDK, ask for `species` == `CellTypesApi.MOUSE`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "kIUTfmJRK9sr",
        "colab_type": "code",
        "outputId": "78910cb1-eb11-435e-d98d-8fead3db20c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from allensdk.api.queries.cell_types_api import CellTypesApi\n",
        "\n",
        "# We want mouse cells that have images and skeletons, both.\n",
        "# Former is data; latter is training labels a.k.a. gold standards.\n",
        "cells = ctc.get_cells(require_reconstruction=True, require_morphology=True, species=[CellTypesApi.MOUSE])\n",
        "print('Number of mouse cells with images and SWC files: %i' % len(cells))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of mouse cells with images and SWC files: 485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "6Zx7RrvNK9su",
        "colab_type": "text"
      },
      "source": [
        "So, The Allen's Cell Types Database can be used as a training dataset consisting of about 500 samples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "full_width"
        ],
        "id": "qFpp7Ea8K9su",
        "colab_type": "text"
      },
      "source": [
        "## References\n",
        "[Cell Types DB Physiology and Morphology whitepaper](http://help.brain-map.org/display/celltypes/Physiology+and+Morphology)\n",
        "\n",
        "[cell_types_cache docs](https://allensdk.readthedocs.io/en/latest/allensdk.core.cell_types_cache.html#allensdk.core.cell_types_cache.CellTypesCache.get_cells)\n"
      ]
    }
  ]
}